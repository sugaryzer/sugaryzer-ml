{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0vSLA7sc_PLv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from typing import Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_category_embeddings(categories):\n",
        "    vocabulary = sorted(list(set(categories)))\n",
        "    cat_to_idx = {cat: idx for idx, cat in enumerate(vocabulary)}\n",
        "\n",
        "    num_categories = len(vocabulary)\n",
        "    one_hot = np.zeros((len(categories), num_categories))\n",
        "    for i, cat in enumerate(categories):\n",
        "        one_hot[i, cat_to_idx[cat]] = 1\n",
        "\n",
        "    return one_hot, vocabulary\n",
        "\n",
        "def cosine_similarity_matrix(vectors):\n",
        "    normalized = tf.nn.l2_normalize(vectors, axis=1)\n",
        "    similarity = tf.matmul(normalized, normalized, transpose_b=True)\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "dZwKdzAF_Rhl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TFRecommender:\n",
        "    def __init__(self):\n",
        "        self.category_matrix = None\n",
        "        self.vocabulary = None\n",
        "        self.data = None\n",
        "        self.similarity_matrix = None\n",
        "\n",
        "    def fit(self, data):\n",
        "        self.data = data\n",
        "        categories = data['category'].values\n",
        "\n",
        "        self.category_matrix, self.vocabulary = create_category_embeddings(categories)\n",
        "        self.similarity_matrix = cosine_similarity_matrix(\n",
        "            tf.constant(self.category_matrix, dtype=tf.float32)\n",
        "        )\n",
        "\n",
        "    def get_nearest_neighbors(self, idx, k=10):\n",
        "        similarities = self.similarity_matrix[idx]\n",
        "        values, indices = tf.math.top_k(similarities, k=k+1)\n",
        "        return values[1:].numpy(), indices[1:].numpy()\n",
        "\n",
        "def recommend_low_sugar_tf(recommender, data, product_id, n=5, sugar_threshold=20):\n",
        "    if product_id not in data['product_id'].values:\n",
        "        return f\"Produk dengan ID '{product_id}' tidak ditemukan dalam dataset.\"\n",
        "\n",
        "    product_index = data[data['product_id'] == product_id].index[0]\n",
        "\n",
        "    similarities, indices = recommender.get_nearest_neighbors(product_index, k=n*2)\n",
        "\n",
        "    recommended_lowsugar = []\n",
        "    for idx in indices:\n",
        "        product_name = data.iloc[idx]['product_name']\n",
        "        sugar_content = data.iloc[idx]['sugar_intake']\n",
        "\n",
        "        if pd.notna(sugar_content) and sugar_content < sugar_threshold:\n",
        "            recommended_lowsugar.append({\n",
        "                'product_id': data.iloc[idx]['product_id'],\n",
        "                'product_name': product_name,\n",
        "                'category': data.iloc[idx]['category'],\n",
        "                'sugar_intake': sugar_content,\n",
        "                'similarity': similarities[len(recommended_lowsugar)]\n",
        "            })\n",
        "\n",
        "        if len(recommended_lowsugar) >= n:\n",
        "            break\n",
        "\n",
        "    if not recommended_lowsugar:\n",
        "        return f\"Tidak ada produk rendah gula yang ditemukan di sekitar produk ID '{product_id}'.\"\n",
        "\n",
        "    recommended_lowsugar_data = pd.DataFrame(recommended_lowsugar)\n",
        "    return recommended_lowsugar_data[['product_id', 'product_name', 'category', 'sugar_intake', 'similarity']]\n",
        "\n",
        "def evaluate_recommendation_system_tf(recommender, data, test_products, n=5, sugar_threshold=20):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    sugar_differences = []\n",
        "    diversity_scores = []\n",
        "\n",
        "    for product_id in test_products:\n",
        "        if product_id not in data['product_id'].values:\n",
        "            print(f\"Produk dengan ID '{product_id}' tidak ditemukan dalam dataset.\")\n",
        "            continue\n",
        "\n",
        "        recommended = recommend_low_sugar_tf(recommender, data, product_id, n=n, sugar_threshold=sugar_threshold)\n",
        "\n",
        "        if isinstance(recommended, str):\n",
        "            print(recommended)\n",
        "            continue\n",
        "\n",
        "        correct_recommendations = recommended['sugar_intake'] < sugar_threshold\n",
        "        precision = correct_recommendations.sum() / len(recommended)\n",
        "        precision_scores.append(precision)\n",
        "\n",
        "        input_category = data.loc[data['product_id'] == product_id, 'category'].values[0]\n",
        "        possible_low_sugar = data[(data['category'] == input_category) & (data['sugar_intake'] < sugar_threshold)]\n",
        "        recall = correct_recommendations.sum() / len(possible_low_sugar) if len(possible_low_sugar) > 0 else 0\n",
        "        recall_scores.append(recall)\n",
        "\n",
        "        input_sugar = data.loc[data['product_id'] == product_id, 'sugar_intake'].values[0]\n",
        "        avg_difference = (input_sugar - recommended['sugar_intake']).mean()\n",
        "        sugar_differences.append(avg_difference)\n",
        "\n",
        "        diversity = recommended['category'].nunique()\n",
        "        diversity_scores.append(diversity)\n",
        "\n",
        "    metrics = {\n",
        "        'Average Precision': np.mean(precision_scores) if precision_scores else 0,\n",
        "        'Average Recall': np.mean(recall_scores) if recall_scores else 0,\n",
        "        'Average Sugar Difference': np.mean(sugar_differences) if sugar_differences else 0,\n",
        "        'Average Diversity': np.mean(diversity_scores) if diversity_scores else 0\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "Mdw6A6NR_XQf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"products_fixed.csv\")\n",
        "data['sugar_intake'] = data['sugar_intake'].str.replace(',', '.').astype(float)\n",
        "\n",
        "recommender = TFRecommender()\n",
        "recommender.fit(data)\n",
        "\n",
        "product_id = 8998888121943\n",
        "n_recommendations = 10\n",
        "sugar_threshold = 20\n",
        "\n",
        "result = recommend_low_sugar_tf(recommender, data, product_id, n_recommendations, sugar_threshold)\n",
        "print(\"\\nRecommendations:\")\n",
        "print(result)\n",
        "\n",
        "test_products = data['product_id'].sample(10).tolist()\n",
        "metrics = evaluate_recommendation_system_tf(recommender, data, test_products, n=5, sugar_threshold=20)\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"{metric}: {value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MJczXe__byf",
        "outputId": "bfa03240-fc5d-475e-9355-675e913b1ee4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommendations:\n",
            "      product_id                                       product_name  \\\n",
            "0  8992696527447  Nescafe Minuman Kopi Susu Rasa Coconut Latte C...   \n",
            "1  8998866202893            Golda Minuman Kopi Cappucino Pet 200 ml   \n",
            "2  8998866201841          Golda Minuman Kopi Dolce Latte Pet 200 ml   \n",
            "3  9556001288592                   Nescafe Latte Kopi Kaleng 220 ml   \n",
            "4  8991002122017                       ABC Minuman Kopi Susu 200 ml   \n",
            "5  8994171102101             Luwak White Koffie Original Pet 220 ml   \n",
            "6  8991002122000              ABC Minuman Kopi Chocomalt Pet 200 ml   \n",
            "7  9556001295248               Nescafe Minuman Es Kopi Hitam 220 ml   \n",
            "8  9556001288547              Nescafe Cappuccino Kopi Kaleng 220 ml   \n",
            "9  9556001288561       Nescafe Caramel Macchiato Kopi Kaleng 220 ml   \n",
            "\n",
            "          category  sugar_intake  similarity  \n",
            "0  Kopi Siap Minum          14.0         1.0  \n",
            "1  Kopi Siap Minum          19.0         1.0  \n",
            "2  Kopi Siap Minum          15.0         1.0  \n",
            "3  Kopi Siap Minum          18.0         1.0  \n",
            "4  Kopi Siap Minum          18.0         1.0  \n",
            "5  Kopi Siap Minum          12.0         1.0  \n",
            "6  Kopi Siap Minum          18.0         1.0  \n",
            "7  Kopi Siap Minum          12.0         1.0  \n",
            "8  Kopi Siap Minum          14.0         1.0  \n",
            "9  Kopi Siap Minum          16.0         1.0  \n",
            "\n",
            "Evaluation Metrics:\n",
            "Average Precision: 1.00\n",
            "Average Recall: 0.13\n",
            "Average Sugar Difference: 5.98\n",
            "Average Diversity: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RecommenderModel:\n",
        "    def __init__(self):\n",
        "        self.category_matrix = None\n",
        "        self.vocabulary = None\n",
        "        self.product_data = None\n",
        "        self.product_id_to_index = None\n",
        "        self.tflite_model = None\n",
        "\n",
        "    def preprocess_data(self, data: pd.DataFrame) -> None:\n",
        "        self.product_data = data.copy()\n",
        "        # index mapping\n",
        "        self.product_id_to_index = {pid: idx for idx, pid in enumerate(data['product_id'])}\n",
        "\n",
        "        # category embeddings\n",
        "        categories = data['category'].values\n",
        "        vocabulary = sorted(list(set(categories)))\n",
        "        cat_to_idx = {cat: idx for idx, cat in enumerate(vocabulary)}\n",
        "\n",
        "        num_categories = len(vocabulary)\n",
        "        one_hot = np.zeros((len(categories), num_categories))\n",
        "        for i, cat in enumerate(categories):\n",
        "            one_hot[i, cat_to_idx[cat]] = 1\n",
        "\n",
        "        self.category_matrix = one_hot\n",
        "        self.vocabulary = vocabulary\n",
        "\n",
        "    def create_tflite_model(self) -> None:\n",
        "        class SimilarityModel(tf.Module):\n",
        "            def __init__(self, category_matrix):\n",
        "                super().__init__()\n",
        "                self.category_matrix = tf.Variable(category_matrix, dtype=tf.float32)\n",
        "\n",
        "            @tf.function(input_signature=[tf.TensorSpec(shape=(), dtype=tf.int32)])\n",
        "            def compute_similarities(self, product_idx):\n",
        "                product_vector = tf.gather(self.category_matrix, product_idx)\n",
        "                product_vector = tf.expand_dims(product_vector, 0)\n",
        "\n",
        "                product_norm = tf.nn.l2_normalize(product_vector, axis=1)\n",
        "                matrix_norm = tf.nn.l2_normalize(self.category_matrix, axis=1)\n",
        "\n",
        "                #similarity scores\n",
        "                similarities = tf.matmul(product_norm, matrix_norm, transpose_b=True)\n",
        "                return tf.squeeze(similarities)\n",
        "\n",
        "        # create and convert model\n",
        "        model = SimilarityModel(self.category_matrix)\n",
        "        converter = tf.lite.TFLiteConverter.from_concrete_functions(\n",
        "            [model.compute_similarities.get_concrete_function()])\n",
        "\n",
        "        converter.target_spec.supported_ops = [\n",
        "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "            tf.lite.OpsSet.SELECT_TF_OPS\n",
        "        ]\n",
        "\n",
        "        self.tflite_model = converter.convert()\n",
        "\n",
        "    def save_model(self, model_path: str, metadata_path: str) -> None:\n",
        "        # save TFLite model\n",
        "        with open(model_path, 'wb') as f:\n",
        "            f.write(self.tflite_model)\n",
        "\n",
        "        # save metadata (product data and mappings)\n",
        "        metadata = {\n",
        "            'product_id_to_index': self.product_id_to_index,\n",
        "            'products': self.product_data.to_dict('records')\n",
        "        }\n",
        "        pd.to_pickle(metadata, metadata_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_recommendations(\n",
        "        product_id: int,\n",
        "        tflite_model_path: str,\n",
        "        metadata_path: str,\n",
        "        n_recommendations: int = 5,\n",
        "        sugar_threshold: float = 20.0\n",
        "    ) -> List[Dict]:\n",
        "        # load metadata\n",
        "        metadata = pd.read_pickle(metadata_path)\n",
        "        product_id_to_index = metadata['product_id_to_index']\n",
        "        products = pd.DataFrame(metadata['products'])\n",
        "\n",
        "        if product_id not in product_id_to_index:\n",
        "            raise ValueError(f\"Product ID {product_id} not found in the dataset\")\n",
        "\n",
        "        interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "        interpreter.allocate_tensors()\n",
        "\n",
        "        # get input and output details\n",
        "        input_details = interpreter.get_input_details()\n",
        "        output_details = interpreter.get_output_details()\n",
        "\n",
        "        product_idx = product_id_to_index[product_id]\n",
        "        interpreter.set_tensor(input_details[0]['index'], np.array(product_idx, dtype=np.int32))\n",
        "\n",
        "        interpreter.invoke()\n",
        "        similarities = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "        # get top similar products with low sugar\n",
        "        similar_indices = np.argsort(similarities)[::-1]\n",
        "        recommendations = []\n",
        "\n",
        "        for idx in similar_indices:\n",
        "            if idx == product_idx:\n",
        "                continue\n",
        "\n",
        "            product = products.iloc[idx]\n",
        "            sugar_content = product['sugar_intake']\n",
        "\n",
        "            if pd.notna(sugar_content) and sugar_content < sugar_threshold:\n",
        "                recommendations.append({\n",
        "                    'product_id': product['product_id'],\n",
        "                    'product_name': product['product_name'],\n",
        "                    'category': product['category'],\n",
        "                    'sugar_intake': sugar_content,\n",
        "                    'similarity': similarities[idx]\n",
        "                })\n",
        "\n",
        "            if len(recommendations) >= n_recommendations:\n",
        "                break\n",
        "\n",
        "        return recommendations"
      ],
      "metadata": {
        "id": "Q91lgQZMFjBS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # load and preprocess data\n",
        "    data = pd.read_csv(\"products_fixed.csv\")\n",
        "    data['sugar_intake'] = data['sugar_intake'].str.replace(',', '.').astype(float)\n",
        "\n",
        "    # create and save model\n",
        "    recommender = RecommenderModel()\n",
        "    recommender.preprocess_data(data)\n",
        "    recommender.create_tflite_model()\n",
        "    recommender.save_model('recommender.tflite', 'recommender_metadata.pkl')\n",
        "\n",
        "    # Test recommendations\n",
        "    test_product_id = 8998888121943\n",
        "    recommendations = RecommenderModel.get_recommendations(\n",
        "        product_id=test_product_id,\n",
        "        tflite_model_path='recommender.tflite',\n",
        "        metadata_path='recommender_metadata.pkl',\n",
        "        n_recommendations=5,\n",
        "        sugar_threshold=20.0\n",
        "    )\n",
        "\n",
        "    print(\"\\nRecommendations:\")\n",
        "    for rec in recommendations:\n",
        "        print(f\"Product: {rec['product_name']}\")\n",
        "        print(f\"Category: {rec['category']}\")\n",
        "        print(f\"Total Sugar: {rec['sugar_intake']}g\")\n",
        "        print(f\"Similarity: {rec['similarity']:.2f}\")\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXDDnAr2KdoA",
        "outputId": "eaaa86a9-8d8a-4d85-c24e-5c331589a005"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommendations:\n",
            "Product: Caffino Delizio Oat Cappuccino Minuman Kopi Botol 200 ml\n",
            "Category: Kopi Siap Minum\n",
            "Total Sugar: 15.0g\n",
            "Similarity: 1.00\n",
            "\n",
            "Product: Nescafe Cappuccino Kopi Kaleng 220 ml\n",
            "Category: Kopi Siap Minum\n",
            "Total Sugar: 14.0g\n",
            "Similarity: 1.00\n",
            "\n",
            "Product: F&N Kopi Minuman Soda Kaleng 325 ml\n",
            "Category: Kopi Siap Minum\n",
            "Total Sugar: 12.0g\n",
            "Similarity: 1.00\n",
            "\n",
            "Product: Nescafe Caramel Macchiato Kopi Kaleng 220 ml\n",
            "Category: Kopi Siap Minum\n",
            "Total Sugar: 16.0g\n",
            "Similarity: 1.00\n",
            "\n",
            "Product: Toracafe Minuman Kopi Es Cappuccino 180 ml\n",
            "Category: Kopi Siap Minum\n",
            "Total Sugar: 9.0g\n",
            "Similarity: 1.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def save_and_download_tflite_model(recommender, base_filename='model_recommender'):\n",
        "    os.makedirs('model_export', exist_ok=True)\n",
        "\n",
        "    # save model and metadata\n",
        "    tflite_path = f'model_export/{base_filename}.tflite'\n",
        "    metadata_path = f'model_export/{base_filename}_metadata.pkl'\n",
        "\n",
        "    recommender.save_model(tflite_path, metadata_path)\n",
        "\n",
        "    # create a zip file\n",
        "    zip_path = f'{base_filename}_export.zip'\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        zipf.write(tflite_path, os.path.basename(tflite_path))\n",
        "        zipf.write(metadata_path, os.path.basename(metadata_path))\n",
        "\n",
        "        # Add a README file with instructions\n",
        "        readme_content = \"\"\"\n",
        "Low Sugar Product Recommender Based On Category - TFLite Model\n",
        "\n",
        "Files included:\n",
        "1. recommender.tflite - TensorFlow Lite model file\n",
        "2. recommender_metadata.pkl - Product metadata and mappings\n",
        "\n",
        "Instructions:\n",
        "1. Place both files in your mobile app's assets folder\n",
        "2. Use TensorFlow Lite interpreter to load the model\n",
        "3. Load the metadata file using pickle in Python\n",
        "4. Input : product_id (barcode)\"\"\"\n",
        "\n",
        "        readme_path = 'model_export/README.txt'\n",
        "        with open(readme_path, 'w') as f:\n",
        "            f.write(readme_content)\n",
        "        zipf.write(readme_path, 'README.txt')\n",
        "\n",
        "    # Download the zip file\n",
        "    files.download(zip_path)\n",
        "\n",
        "# Example usage in Colab:\n",
        "def export_model():\n",
        "    # Load and preprocess data\n",
        "    data = pd.read_csv(\"products_fixed.csv\")\n",
        "    data['sugar_intake'] = data['sugar_intake'].str.replace(',', '.').astype(float)\n",
        "\n",
        "    # Create and convert model\n",
        "    recommender = LowSugarRecommenderModel()\n",
        "    recommender.preprocess_data(data)\n",
        "    recommender.create_tflite_model()\n",
        "\n",
        "    # Save and download the model\n",
        "    save_and_download_tflite_model(recommender)\n",
        "\n",
        "    print(\"Model export completed! Check your downloads folder for the zip file.\")\n",
        "\n",
        "# Run the export process\n",
        "export_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "KGO1QnxzH8s2",
        "outputId": "172ed5f1-6ea8-42ae-8d10-11f2faf5fede"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Please consider providing the trackable_obj argument in the from_concrete_functions. Providing without the trackable_obj argument is deprecated and it will use the deprecated conversion path.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb5a7102-b883-44da-a8c6-5cc61d6eb4f7\", \"model_recommender_export.zip\", 57770)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model export completed! Check your downloads folder for the zip file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List\n",
        "\n",
        "def test_tflite_recommender(\n",
        "    tflite_path: str,\n",
        "    metadata_path: str,\n",
        "    test_product_ids: List[int],\n",
        "    n_recommendations: int = 5,\n",
        "    sugar_threshold: float = 20.0\n",
        "):\n",
        "\n",
        "    # load metadata\n",
        "    metadata = pd.read_pickle(metadata_path)\n",
        "    products_df = pd.DataFrame(metadata['products'])\n",
        "    product_id_to_index = metadata['product_id_to_index']\n",
        "\n",
        "    # load TFLite model\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    print(\"Testing TFLite Recommender Model\\n\")\n",
        "    print(\"Model Details:\")\n",
        "    print(f\"Input Shape: {input_details[0]['shape']}\")\n",
        "    print(f\"Input Type: {input_details[0]['dtype']}\")\n",
        "    print(f\"Output Shape: {output_details[0]['shape']}\")\n",
        "    print(f\"Output Type: {output_details[0]['dtype']}\\n\")\n",
        "\n",
        "    for test_id in test_product_ids:\n",
        "        print(f\"\\nTesting Product ID: {test_id}\")\n",
        "\n",
        "        # Get original product details\n",
        "        original_product = products_df[products_df['product_id'] == test_id].iloc[0]\n",
        "        print(\"\\nInput Product:\")\n",
        "        print(f\"Name: {original_product['product_name']}\")\n",
        "        print(f\"Category: {original_product['category']}\")\n",
        "        print(f\"Sugar Content: {original_product['sugar_intake']}g\")\n",
        "\n",
        "        try:\n",
        "            # get product index\n",
        "            product_idx = product_id_to_index[test_id]\n",
        "\n",
        "            # set input tensor\n",
        "            interpreter.set_tensor(input_details[0]['index'],\n",
        "                                np.array(product_idx, dtype=np.int32))\n",
        "\n",
        "            interpreter.invoke()\n",
        "            similarities = interpreter.get_tensor(output_details[0]['index'])\n",
        "            similar_indices = np.argsort(similarities)[::-1]\n",
        "            recommendations = []\n",
        "\n",
        "            print(\"\\nRecommendations:\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            for idx in similar_indices:\n",
        "                if idx == product_idx:\n",
        "                    continue\n",
        "\n",
        "                product = products_df.iloc[idx]\n",
        "                sugar_content = product['sugar_intake']\n",
        "\n",
        "                if pd.notna(sugar_content) and sugar_content < sugar_threshold:\n",
        "                    recommendations.append({\n",
        "                        'product_id': product['product_id'],\n",
        "                        'product_name': product['product_name'],\n",
        "                        'category': product['category'],\n",
        "                        'sugar_intake': sugar_content,\n",
        "                        'similarity': similarities[idx]\n",
        "                    })\n",
        "\n",
        "                    print(f\"\\nProduct: {product['product_name']}\")\n",
        "                    print(f\"Category: {product['category']}\")\n",
        "                    print(f\"Sugar Content: {sugar_content}g\")\n",
        "                    print(f\"Similarity Score: {similarities[idx]:.4f}\")\n",
        "\n",
        "                if len(recommendations) >= n_recommendations:\n",
        "                    break\n",
        "\n",
        "            # verify recommendations\n",
        "            if recommendations:\n",
        "                print(\"\\nVerification Results:\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "                # check category matching\n",
        "                same_category = sum(1 for r in recommendations\n",
        "                                  if r['category'] == original_product['category'])\n",
        "                print(f\"Category Match Rate: {same_category/len(recommendations)*100:.1f}%\")\n",
        "\n",
        "                # check sugar content\n",
        "                all_low_sugar = all(r['sugar_intake'] < sugar_threshold\n",
        "                                  for r in recommendations)\n",
        "                print(f\"All Products Below Sugar Threshold: {'Yes' if all_low_sugar else 'No'}\")\n",
        "\n",
        "                # average similarity score\n",
        "                avg_similarity = np.mean([r['similarity'] for r in recommendations])\n",
        "                print(f\"Average Similarity Score: {avg_similarity:.4f}\")\n",
        "\n",
        "            else:\n",
        "                print(\"\\nNo recommendations found meeting the criteria.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing product {test_id}: {str(e)}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70 + \"\\n\")"
      ],
      "metadata": {
        "id": "FsycWzPoI3Ry"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    test_ids = [\n",
        "        8998009020186,  # product id\n",
        "    ]\n",
        "\n",
        "    test_tflite_recommender(\n",
        "        tflite_path='low_sugar_recommender.tflite',\n",
        "        metadata_path='recommender_metadata.pkl',\n",
        "        test_product_ids=test_ids,\n",
        "        n_recommendations=5,\n",
        "        sugar_threshold=20.0\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZwEfUyULzTm",
        "outputId": "10d671b9-2849-49c2-ce8f-b9bb12874f35"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing TFLite Recommender Model\n",
            "\n",
            "Model Details:\n",
            "Input Shape: []\n",
            "Input Type: <class 'numpy.int32'>\n",
            "Output Shape: [369]\n",
            "Output Type: <class 'numpy.float32'>\n",
            "\n",
            "\n",
            "Testing Product ID: 8998009020186\n",
            "\n",
            "Input Product:\n",
            "Name: Buavita Minuman Sari Buah Jambu 245 mL\n",
            "Category: Jus & Sari Buah\n",
            "Sugar Content: 23.0g\n",
            "\n",
            "Recommendations:\n",
            "--------------------------------------------------\n",
            "\n",
            "Product: Buavita Mini Jus Buah Asli Jeruk 125 ml\n",
            "Category: Jus & Sari Buah\n",
            "Sugar Content: 10.0g\n",
            "Similarity Score: 1.0000\n",
            "\n",
            "Product: Pororo Minuman Rasa Stroberi Botol 235 ml\n",
            "Category: Jus & Sari Buah\n",
            "Sugar Content: 11.0g\n",
            "Similarity Score: 1.0000\n",
            "\n",
            "Product: Ichitan Thai Coco Pet 300 ml\n",
            "Category: Jus & Sari Buah\n",
            "Sugar Content: 18.0g\n",
            "Similarity Score: 1.0000\n",
            "\n",
            "Product: Toza Jus Buah Sirsak 1 L\n",
            "Category: Jus & Sari Buah\n",
            "Sugar Content: 0.0g\n",
            "Similarity Score: 1.0000\n",
            "\n",
            "Product: Pororo Minuman Rasa Mangga Botol 235 ml\n",
            "Category: Jus & Sari Buah\n",
            "Sugar Content: 11.0g\n",
            "Similarity Score: 1.0000\n",
            "\n",
            "Verification Results:\n",
            "--------------------------------------------------\n",
            "Category Match Rate: 100.0%\n",
            "All Products Below Sugar Threshold: Yes\n",
            "Average Similarity Score: 1.0000\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}