# -*- coding: utf-8 -*-
"""TesDeploy_TF Model 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CYHVNLIHl4uJgSoAO5uKLSPoz0hqw0x4
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

#@title Define Callback
class AccuracyThresholdCallback(tf.keras.callbacks.Callback):
    def __init__(self, threshold):
        super(AccuracyThresholdCallback, self).__init__()
        self.threshold = threshold

    def on_epoch_end(self, epoch, logs=None):
        acc = logs.get('accuracy')
        if acc >= self.threshold:
            self.model.stop_training = True

def process_data(file_path):
    data = pd.read_csv(file_path)
    data = data.loc[:, ~data.columns.str.contains('^Unnamed')]
    data.dropna(inplace=True)
    data.drop_duplicates(inplace=True)

    data['Total_Sugar_g'] = pd.to_numeric(data['Total_Sugar_g'], errors='coerce')
    data = data.dropna(subset=['Total_Sugar_g'])

    bins = [0, 30, 35, float('inf')]
    labels = ["hijau", "kuning", "merah"]
    data["consume_category"] = pd.cut(data['Total_Sugar_g'], bins=bins, labels=labels)

    return data

class SugarConsumptionClassifier:
    def __init__(self):
        self.model = None
        self.label_encoder = LabelEncoder()
        self.history = None

    from tensorflow.keras.regularizers import l2

    def create_model(input_shape):
        model = models.Sequential([
            layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01), input_shape=input_shape),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(16, activation='relu', kernel_regularizer=l2(0.01)),
            layers.BatchNormalization(),
            layers.Dropout(0.3),

            layers.Dense(3, activation='softmax')  # 3 kategori output
        ])

        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        return model

    def fit(self, X_train, y_train, X_val, y_val, epochs=100):
        # Encode labels
        y_train_encoded = self.label_encoder.fit_transform(y_train)
        y_val_encoded = self.label_encoder.transform(y_val)

        self.model = self.create_model((1,))

        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=10,
            restore_best_weights=True
        )

        accuracy_threshold = AccuracyThresholdCallback(threshold=0.95)
        self.history = self.model.fit(
            X_train, y_train_encoded,
            validation_data=(X_val, y_val_encoded),
            epochs=epochs,
            batch_size=10,
            callbacks=[early_stopping, accuracy_threshold],
            verbose=1
        )

    def predict(self, X):
        predictions = self.model.predict(X)
        predicted_classes = np.argmax(predictions, axis=1)
        return self.label_encoder.inverse_transform(predicted_classes)

    def evaluate(self, X_test, y_test):
        y_test_encoded = self.label_encoder.transform(y_test)
        loss, accuracy = self.model.evaluate(X_test, y_test_encoded)

        y_pred = self.predict(X_test)

        conf_matrix = tf.math.confusion_matrix(
            y_test_encoded,
            self.label_encoder.transform(y_pred)
        )
        report = classification_report_custom(y_test, y_pred)

        return {
            'accuracy': accuracy,
            'confusion_matrix': conf_matrix.numpy(),
            'classification_report': report
        }

    def plot_training_history(self):
        plt.figure(figsize=(12, 4))

        # Plot accuracy
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['accuracy'], label='Training Accuracy')
        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        plt.title('Model Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()

        # Plot loss
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('Model Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()

        plt.tight_layout()
        plt.show()

def classification_report_custom(y_true, y_pred):
    labels = sorted(list(set(y_true)))
    report = {}

    for label in labels:
        true_pos = np.sum((y_true == label) & (y_pred == label))
        false_pos = np.sum((y_true != label) & (y_pred == label))
        false_neg = np.sum((y_true == label) & (y_pred != label))

        precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0
        recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        report[label] = {
            'precision': precision,
            'recall': recall,
            'f1-score': f1
        }

    return report

def plot_category_distribution(data):
    categories = ['Hijau', 'Kuning', 'Merah']
    counts = [
        (data["consume_category"] == "hijau").sum(),
        (data["consume_category"] == "kuning").sum(),
        (data["consume_category"] == "merah").sum()
    ]

    plt.figure(figsize=(10, 6))
    bars = plt.bar(categories, counts, color=['green', 'yellow', 'red'])
    plt.xlabel('Kategori Konsumsi Gula')
    plt.ylabel('Jumlah Pengkonsumsi')
    plt.title('Distribusi Kategori Konsumsi Gula')

    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}',
                ha='center', va='bottom')

    plt.show()

def predict_sugar_category(model, daily_sugar_intake):
    if not isinstance(daily_sugar_intake, (int, float)):
        return "Input konsumsi gula harian tidak valid. Harap masukkan angka."

    input_data = np.array([[daily_sugar_intake]])
    prediction = model.predict(input_data)

    category = prediction[0]
    advice = {
        "hijau": "Konsumsi gula harian di bawah normal.",
        "kuning": "Konsumsi gula harian normal.",
        "merah": "Konsumsi gula harian berlebihan."
    }

    return {
        'category': category,
        'advice': advice[category]
    }

if __name__ == "__main__":
    data = process_data("/content/consume.csv")

    X = data[['Total_Sugar_g']].values
    y = data['consume_category']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

    # Menggunakan semua teknik
    X_train_augmented = augment_data(X_train, noise_level=0.05)

    classifier = SugarConsumptionClassifier()
    classifier.create_model((1,))
    classifier.fit(X_train_augmented, y_train, X_val, y_val, epochs=100)

    evaluation = classifier.evaluate(X_test, y_test)
    print("\nModel Evaluation:")
    print(f"Accuracy: {evaluation['accuracy']:.2%}")
    print("\nConfusion Matrix:")
    print(evaluation['confusion_matrix'])
    print("\nClassification Report:")
    print(evaluation['classification_report'])


    classifier.plot_training_history()
    plot_category_distribution(data)

    daily_sugar_intake = 70
    result = predict_sugar_category(classifier, daily_sugar_intake)
    print(f"\nKonsumsi gula harian: {daily_sugar_intake}g")
    print(f"Kategori: {result['category']}")
    print(f"Saran: {result['advice']}")